{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instruments as inst\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.a): Reading in csv - extracting single diffs and sums and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Interleaved Values\n",
      "Length:  320\n",
      "[ 19866.   23740.5 -22265.5  22477.5  13337.5  22094.5 -15543.5  21181.5\n",
      "  -1825.5  18824. ]\n",
      "Interleaved Stds\n",
      "Length:  320\n",
      "[688.95936526 798.7614491  791.45797182 797.27596033 531.8586925\n",
      " 800.67495167 727.56322485 816.37585171 198.75093928 698.70510581]\n",
      "Configuration List\n",
      "Length:  160\n",
      "[{'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 45.0}}, {'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 45.0}}, {'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 57.5}}, {'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 57.5}}, {'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 70.0}}, {'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 70.0}}, {'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 82.5}}, {'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 82.5}}, {'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 95.0}}, {'hwp': {'theta': 0.0}, 'image_rotator': {'theta': 95.0}}]\n",
      "688.95936526\n"
     ]
    }
   ],
   "source": [
    "file_path = \"20230914_processed_table.csv\"\n",
    "wavelength_string = 610\n",
    "obs_mode = \"MBI\"\n",
    "\n",
    "interleaved_values, interleaved_stds, configuration_list = inst.read_csv(file_path, \n",
    "    obs_mode = obs_mode, obs_filter = wavelength_string)\n",
    "print(\"Interleaved Values\")\n",
    "print(\"Length: \", len(interleaved_values))\n",
    "print(interleaved_values[0 : 10])\n",
    "print(\"Interleaved Stds\")\n",
    "print(\"Length: \", len(interleaved_stds))\n",
    "print(interleaved_stds[0 : 10])\n",
    "print(\"Configuration List\")\n",
    "print(\"Length: \", len(configuration_list))\n",
    "print(configuration_list[0 : 10])\n",
    "print(interleaved_stds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1.b) - Make plot of existing values as double diffs and sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Creating a system Mueller matrix object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past Fit:  [ 1.53307627  0.46163077 -2.3687464   0.32815156 -4.99600063 -0.20433489\n",
      "  0.02210595 18.49730849  0.52007057  4.99645591  1.19152714]\n"
     ]
    }
   ],
   "source": [
    "# Loading in previous fit from vampires_calibration\n",
    "past_fit = np.load(\"scipy_minimize_20230914_675nm_restrictive_HWP_and_IMR.npy\")\n",
    "print(\"Past Fit: \", past_fit)\n",
    "\n",
    "theta_pol = past_fit[0]\n",
    "delta_HWP = past_fit[1]\n",
    "offset_HWP = past_fit[2]\n",
    "delta_derot = past_fit[3]\n",
    "offset_derot = past_fit[4]\n",
    "delta_opts = past_fit[5]\n",
    "epsilon_opts = past_fit[6]\n",
    "rot_opts = past_fit[7]\n",
    "delta_FLC = past_fit[8]\n",
    "rot_FLC = past_fit[9]\n",
    "em_gain = past_fit[10]\n",
    "\n",
    "# NOTE: Components must be listed downstream to upstream\n",
    "# Define the instrument configuration as a system dictionary\n",
    "system_dict = {\n",
    "    \"components\": {\n",
    "        \"wollaston\": {\n",
    "            \"type\": \"wollaston_prism_function\",\n",
    "            \"properties\": {\"beam\": \"o\", \"transmission_ratio\": em_gain},\n",
    "        },\n",
    "        \"dichroic\": {\n",
    "            \"type\": \"general_retarder_function\",\n",
    "            \"properties\": {\"phi\": 0, \"theta\": 0},\n",
    "        },\n",
    "        \"flc\": {\n",
    "            \"type\": \"general_retarder_function\",\n",
    "            \"properties\": {\"phi\": 2 * np.pi * delta_FLC, \"theta\": 0, \"delta_theta\": rot_FLC},\n",
    "        },\n",
    "        \"optics\": {\n",
    "            \"type\": \"diattenuator_retarder_function\",\n",
    "            \"properties\": {\"phi\": 2 * np.pi * delta_opts, \"epsilon\": epsilon_opts, \"theta\": rot_opts},\n",
    "        },\n",
    "        \"image_rotator\": {\n",
    "            \"type\": \"general_retarder_function\",\n",
    "            \"properties\": {\"phi\": 2 * np.pi * delta_derot, \"theta\": 0, \"delta_theta\": offset_derot},\n",
    "        },\n",
    "        \"hwp\": {\n",
    "            \"type\": \"general_retarder_function\",\n",
    "            \"properties\": {\"phi\": 2 * np.pi * delta_HWP, \"theta\": 0, \"delta_theta\": offset_HWP},\n",
    "        },\n",
    "        \"lp\": {\n",
    "            \"type\": \"general_linear_polarizer_function_with_theta\",\n",
    "            \"properties\": {\"theta\": theta_pol},\n",
    "        },\n",
    "        # Testing whether generate_system_mueller_matrix can flag this as a non-existent component\n",
    "        \"test_false_type\": {\n",
    "            \"type\": \"test\",\n",
    "            \"properties\": {\"theta\": 0, \"epsilon\": 0}\n",
    "        },\n",
    "        # Testing whether generate_system_mueller_matrix can flag epsilon as a\n",
    "        # non-existent property of rotator\n",
    "        \"test_false_property\": {\n",
    "            \"type\": \"general_retarder_function\",\n",
    "            \"properties\": {\"epsilon\": 0}\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'test' is not a valid function in pyMuellerMat.common_mm_functions and will be skipped.\n",
      "Warning: Component 'test_false_property' has invalid properties ['epsilon']. These properties will be ignored.\n",
      "Warning: Component 'test_false_property' has no valid properties and will be skipped.\n",
      "[[0.51859792 0.51785552 0.02773924 0.        ]\n",
      " [0.51859792 0.51785552 0.02773924 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Converting system dictionary into system Mueller Matrix object\n",
    "\n",
    "system_mm = inst.generate_system_mueller_matrix(system_dict)\n",
    "print(system_mm.evaluate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST: Checking parse_configuration & update_system_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: [0.0, 0.0, 0.0, 0.0, 'o']\n",
      "Keywords: [['lp', 'theta'], ['hwp', 'theta'], ['image_rotator', 'theta'], ['flc', 'theta'], ['wollaston', 'beam']]\n"
     ]
    }
   ],
   "source": [
    "test_configuration = {\n",
    "    'lp': {'theta': 0.0},\n",
    "    'hwp': {'theta': 0.0},\n",
    "    'image_rotator': {'theta': 0.0},\n",
    "    'flc': {'theta': 0.0},\n",
    "    'wollaston': {'beam': 'o'}\n",
    "    }\n",
    "\n",
    "values, keywords = inst.parse_configuration(test_configuration)\n",
    "print(\"Values: \" + str(values))\n",
    "print(\"Keywords: \" + str(keywords))\n",
    "\n",
    "updated_system_mm = inst.update_system_mm(values, keywords, system_mm)\n",
    "# print(updated_system_mm.evaluate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Creating a dictionary of p0 starting guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fittin for just the dichroic for now\n",
    "\n",
    "p0 = {\n",
    "    \"dichroic\": {\"phi\": 0, \"theta\": 0}\n",
    "}\n",
    "\n",
    "p0_values, p0_keywords = inst.parse_configuration(p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Running minimize_system_Mueller_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0_values:  [0, 0]\n",
      "p0_keywords:  [['dichroic', 'phi'], ['dichroic', 'theta']]\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "Entered logl\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Output Intensities:  (160,)\n",
      "Pre process_dataset dataset shape:  (320,)\n",
      "Entered process_dataset\n",
      "Pre np.array Input dataset:  (320,)\n",
      "Post np.array Input dataset:  (320,)\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Post process_dataset dataset shape:  (160,)\n",
      "Pre process_errors errors shape:  (320,)\n",
      "Entered process_errors\n",
      "Pre-processing Errors shape:  (320,)\n",
      "Pre-processing Dataset shape:  (320,)\n",
      "Differences Errors shape:  (160,)\n",
      "Sums Errors shape:  (160,)\n",
      "Double Differences Errors shape:  (80,)\n",
      "Double Sums Errors shape:  (80,)\n",
      "Final interleaved Errors shape:  (160,)\n",
      "Post process_errors errors shape:  (160,)\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Unpolarized light for s_in as there is LP in the system already\n",
    "s_in = np.array([1, 0, 0, 0])\n",
    "\n",
    "result = inst.minimize_system_mueller_matrix(p0, system_mm, interleaved_values, \n",
    "    interleaved_stds, configuration_list, s_in = s_in,\n",
    "    process_dataset = inst.process_dataset, process_errors = inst.process_errors, \n",
    "    process_model = inst.process_model)\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Plot model with best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0.]\n",
      "[['dichroic', 'phi'], ['dichroic', 'theta']]\n",
      "Entered process_model\n",
      "Differences shape:  (160,)\n",
      "Sums shape:  (160,)\n",
      "Double Differences shape:  (80,)\n",
      "Double Sums shape:  (80,)\n",
      "Model Length: 160\n"
     ]
    }
   ],
   "source": [
    "# Generate model with p0 keywords but scipy minimized results\n",
    "\n",
    "print(result.x)\n",
    "print(p0_keywords)\n",
    "\n",
    "updated_system_mm = inst.update_system_mm(result.x, p0_keywords, system_mm)\n",
    "model = inst.model(result.x, p0_keywords, system_mm, configuration_list, process_model = inst.process_model)\n",
    "print(\"Model Length:\", len(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
